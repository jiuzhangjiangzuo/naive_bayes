{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9fc86914-828d-4a46-ba7f-c1f4980e1cc9",
    "_uuid": "89d41aa529dd673b83937281bec04f0a75af8b54"
   },
   "source": [
    "# Movie Sentiment Analysis\n",
    "https://www.kaggle.com/c/word2vec-nlp-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d6b1ab40-34da-4645-98c4-4b61c97895f6",
    "_uuid": "0259bd59e4fad41ffd78aa5a510a83ef07daab7f",
    "collapsed": true
   },
   "source": [
    " 拿到数据首先读入拿到数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "a89760f4-9075-42be-b4c4-c8c87d175c88",
    "_uuid": "4429a082ddabcb23261daec29ee1ae9e68ba2a2e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt # 画图常用库\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train = pd.read_csv('../input/labeledTrainData.tsv', delimiter=\"\\t\")\n",
    "test = pd.read_csv('../input/testData.tsv', delimiter=\"\\t\")\n",
    "train.head()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "76be376a-0c66-4001-ac99-9b968ce62781",
    "_uuid": "bc7497787d1d19eee918fec0faabe29669a8b3fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "# test data比如train data少了label的一维\n",
    "print (train.shape)\n",
    "print (test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "708ea854-0c20-4ac0-97b7-90075d8f63c4",
    "_uuid": "ad1c1cf6085fdf9d83c34c68b324f1c73e710315"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    清理数据，文本中包含HTML的符号比如<>，我们使用正则表达式简单地清理一下\n",
    "'''\n",
    "import re  #正则表达式\n",
    "\n",
    "def review_preprocessing(review):\n",
    "    #只保留英文单词\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "    \n",
    "    #变成小写\n",
    "    words = review_text.lower()\n",
    "    \n",
    "    return(words)\n",
    "\n",
    "# 把训练集的文本和标注分开\n",
    "# 1. 把标注提取出来\n",
    "full_train_y = train['sentiment']\n",
    "\n",
    "# 2. 把文本提取出来\n",
    "full_train_x = []\n",
    "for review in train['review']:\n",
    "    full_train_x.append(review_preprocessing(review))\n",
    "    \n",
    "# 3. 转化成numpy数组        \n",
    "full_train_x = np.array(full_train_x)\n",
    "\n",
    "# 对校验集的文本做同样的事情\n",
    "\n",
    "\n",
    "# 对测试集的文本做同样的事情\n",
    "test_data = []\n",
    "for review in test['review']:\n",
    "    test_data.append(review_preprocessing(review))\n",
    "    \n",
    "test_data = np.array(test_data)\n",
    "\n",
    "print(full_train_x.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_data => split(train_set, validation_set) => 选出好的模型 => optional(retrain_on_fulldata) => 训练好的模型 => test \n",
    "data_train, data_validation, labels_train, labels_validation = train_test_split(\n",
    "    full_train_x,\n",
    "    full_train_y, \n",
    "    test_size=0.2, \n",
    "    random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "2514583c-d410-4dd8-9ce2-db907d4e3750",
    "_uuid": "83cd36c185194d6513246af09afb76e20241b380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's go!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 使用简单的计数\n",
    "vectorizer = CountVectorizer()\n",
    "data_train_count = vectorizer.fit_transform(data_train)\n",
    "data_validation_count  = vectorizer.transform(data_validation)\n",
    "\n",
    "print(\"Let's go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "\n",
    "tfidf_data_train_count = tfidf_vectorizer.fit_transform(data_train)\n",
    "tfidf_data_validation_count  = tfidf_vectorizer.transform(data_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用tf-idf with n-gram and stop words\n",
    "advance_tfidf_vectorizer = TfidfVectorizer(\n",
    "           ngram_range=(1, 3),  # 二元文法模型\n",
    "           stop_words = 'english') # 去掉英文停用词\n",
    "\n",
    "\n",
    "advance_tfidf_data_train_count = advance_tfidf_vectorizer.fit_transform(data_train)\n",
    "advance_tfidf_data_validation_count  = advance_tfidf_vectorizer.transform(data_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "a50a42b3-659d-470d-bef6-cc96d4b87935",
    "_uuid": "1df60d0c5595dbef07726f082c0c25336be8f56c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter Accuracy: 0.8624\n",
      "TFIDF Accuracy: 0.8762\n",
      "Advance TFIDF Accuracy: 0.8846\n"
     ]
    }
   ],
   "source": [
    "# 多项式朴素贝叶斯\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# 用Validation Set选择模型\n",
    "clf.fit(data_train_count, labels_train)\n",
    "pred = clf.predict(data_validation_count)\n",
    "print (\"Counter Accuracy:\", accuracy_score(labels_validation, pred))\n",
    "\n",
    "clf.fit(tfidf_data_train_count, labels_train)\n",
    "tfidf_pred = clf.predict(tfidf_data_validation_count)\n",
    "print (\"TFIDF Accuracy:\", accuracy_score(labels_validation, tfidf_pred))\n",
    "\n",
    "clf.fit(advance_tfidf_data_train_count, labels_train)\n",
    "advance_tfidf_pred = clf.predict(advance_tfidf_data_validation_count)\n",
    "print (\"Advance TFIDF Accuracy:\", accuracy_score(labels_validation, advance_tfidf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "# 全量训练\n",
    "full_data_train_count = advance_tfidf_vectorizer.fit_transform(full_train_x)\n",
    "data_test_count  = advance_tfidf_vectorizer.transform(test_data)\n",
    "clf.fit(full_data_train_count, full_train_y)\n",
    "\n",
    "# 最终测试\n",
    "pred = clf.predict(data_test_count)\n",
    "print(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "92e53d2f-36a2-4563-94be-bd4180d91ce6",
    "_uuid": "f87c65946b352d663140864a1ee81adc7b3c94dd"
   },
   "outputs": [],
   "source": [
    "# 把结果保存到csv文件中，并进行提交: https://www.kaggle.com/c/word2vec-nlp-tutorial/leaderboard\n",
    "df = pd.DataFrame({\"id\": test['id'],\"sentiment\": pred})\n",
    "\n",
    "df.to_csv('submission.csv',index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
